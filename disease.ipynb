{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Aug  8 09:50:43 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.43.04    Driver Version: 515.43.04    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   43C    P5     8W /  N/A |   2027MiB /  4096MiB |     39%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      3303      G   /usr/lib/xorg/Xorg                157MiB |\n",
      "|    0   N/A  N/A      3621      G   ...ome-remote-desktop-daemon        1MiB |\n",
      "|    0   N/A  N/A      3658      G   /usr/bin/gnome-shell              139MiB |\n",
      "|    0   N/A  N/A      4915      G   ...RendererForSitePerProcess      144MiB |\n",
      "|    0   N/A  N/A      5463      C   /bin/python3                     1579MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import torch \n",
    "from torchvision import datasets , transforms , models \n",
    "from torch.utils.data.sampler import SubsetRandomSampler \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from datetime import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose( \n",
    "    [ \n",
    "        transforms.Resize(255) , transforms.CenterCrop(224) , transforms.ToTensor() ,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(\"./data/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/\" , transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 70295\n",
       "    Root location: ./data/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=255, interpolation=bilinear, max_size=None, antialias=None)\n",
       "               CenterCrop(size=(224, 224))\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70295"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = list(range(len(dataset)))\n",
    "len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 41825 59750 70295\n"
     ]
    }
   ],
   "source": [
    "split = int(np.floor(0.85*len(dataset)))\n",
    "validation = int(np.floor(0.70*split)) \n",
    "print(0 , validation , split , len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train size :41825\n",
      "length of validation size :17925\n",
      "length of test size :28470\n"
     ]
    }
   ],
   "source": [
    "print(f\"length of train size :{validation}\")\n",
    "print(f\"length of validation size :{split - validation}\")\n",
    "print(f\"length of test size :{len(dataset)-validation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices , validation_indices , test_indices = ( \n",
    "    indices[:validation] , indices[validation:split] , indices[split:]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(train_indices) \n",
    "validation_sampler = SubsetRandomSampler(validation_indices) \n",
    "test_sampler = SubsetRandomSampler(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_size = len(dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Aithmetic Equation : (W - F + 2P) / S + 1\n",
    "W = Input Size\n",
    "\n",
    "F = Filter Size\n",
    "\n",
    "P = Padding Size\n",
    "\n",
    "S = Stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module): \n",
    "    def __init__(self , K): \n",
    "        super(CNN , self).__init__() \n",
    "        self.conv_layers = nn.Sequential( \n",
    "            \n",
    "            #conv1 \n",
    "            nn.Conv2d(in_channels=3 , out_channels=32  , kernel_size=3 , padding=1),\n",
    "            nn.ReLU() ,\n",
    "            nn.BatchNorm2d(32) , \n",
    "            nn.Conv2d(in_channels=32 , out_channels=32 , kernel_size=3 , padding=1),\n",
    "            nn.ReLU() ,\n",
    "            nn.BatchNorm2d(32) , \n",
    "            nn.MaxPool2d(kernel_size=2 , stride=2) , \n",
    "\n",
    "            #conv2 \n",
    "            nn.Conv2d(in_channels=32 , out_channels=64 , kernel_size=3 , padding=1),\n",
    "            nn.ReLU() ,\n",
    "            nn.BatchNorm2d(64) , \n",
    "            nn.Conv2d(in_channels=64 , out_channels=64 , kernel_size=3 , padding=1),\n",
    "            nn.ReLU() ,\n",
    "            nn.BatchNorm2d(64) , \n",
    "            nn.MaxPool2d(kernel_size=2 , stride=2) , \n",
    "\n",
    "            #conv3 \n",
    "            nn.Conv2d(in_channels=64 , out_channels=128 , kernel_size=3 , padding=1),\n",
    "            nn.ReLU() ,\n",
    "            nn.BatchNorm2d(128) , \n",
    "            nn.Conv2d(in_channels=128 , out_channels=128 , kernel_size=3 , padding=1),\n",
    "            nn.ReLU() ,\n",
    "            nn.BatchNorm2d(128) , \n",
    "            nn.MaxPool2d(kernel_size=2 , stride=2) , \n",
    "            \n",
    "            #conv4 \n",
    "            nn.Conv2d(in_channels=128 , out_channels=256 , kernel_size=3 , padding=1),\n",
    "            nn.ReLU() ,\n",
    "            nn.BatchNorm2d(256) , \n",
    "            nn.Conv2d(in_channels=256 , out_channels=256 , kernel_size=3 , padding=1),\n",
    "            nn.ReLU() ,\n",
    "            nn.BatchNorm2d(256) , \n",
    "            nn.MaxPool2d(kernel_size=2 , stride=2) , \n",
    "        )\n",
    "\n",
    "        self.dense_layers = nn.Sequential( \n",
    "            nn.Dropout(0.4), \n",
    "            nn.Linear(50176 , 1024) ,\n",
    "            nn.ReLU() ,\n",
    "            nn.Dropout(0.4), \n",
    "            nn.Linear(1024 , K) ,\n",
    "        )\n",
    "\n",
    "    def forward(self , X): \n",
    "        out = self.conv_layers(X) \n",
    "\n",
    "        # Flatten \n",
    "        out = out.view(-1 , 50176) \n",
    "\n",
    "        # fully connected \n",
    "        out = self.dense_layers(out) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(targets_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv_layers): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU()\n",
       "    (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU()\n",
       "    (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU()\n",
       "    (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU()\n",
       "    (19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (21): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU()\n",
       "    (23): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (24): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU()\n",
       "    (26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (dense_layers): Sequential(\n",
       "    (0): Dropout(p=0.4, inplace=False)\n",
       "    (1): Linear(in_features=50176, out_features=1024, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=1024, out_features=38, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 256, 14, 14]         --\n",
      "|    └─Conv2d: 2-1                       [-1, 32, 224, 224]        896\n",
      "|    └─ReLU: 2-2                         [-1, 32, 224, 224]        --\n",
      "|    └─BatchNorm2d: 2-3                  [-1, 32, 224, 224]        64\n",
      "|    └─Conv2d: 2-4                       [-1, 32, 224, 224]        9,248\n",
      "|    └─ReLU: 2-5                         [-1, 32, 224, 224]        --\n",
      "|    └─BatchNorm2d: 2-6                  [-1, 32, 224, 224]        64\n",
      "|    └─MaxPool2d: 2-7                    [-1, 32, 112, 112]        --\n",
      "|    └─Conv2d: 2-8                       [-1, 64, 112, 112]        18,496\n",
      "|    └─ReLU: 2-9                         [-1, 64, 112, 112]        --\n",
      "|    └─BatchNorm2d: 2-10                 [-1, 64, 112, 112]        128\n",
      "|    └─Conv2d: 2-11                      [-1, 64, 112, 112]        36,928\n",
      "|    └─ReLU: 2-12                        [-1, 64, 112, 112]        --\n",
      "|    └─BatchNorm2d: 2-13                 [-1, 64, 112, 112]        128\n",
      "|    └─MaxPool2d: 2-14                   [-1, 64, 56, 56]          --\n",
      "|    └─Conv2d: 2-15                      [-1, 128, 56, 56]         73,856\n",
      "|    └─ReLU: 2-16                        [-1, 128, 56, 56]         --\n",
      "|    └─BatchNorm2d: 2-17                 [-1, 128, 56, 56]         256\n",
      "|    └─Conv2d: 2-18                      [-1, 128, 56, 56]         147,584\n",
      "|    └─ReLU: 2-19                        [-1, 128, 56, 56]         --\n",
      "|    └─BatchNorm2d: 2-20                 [-1, 128, 56, 56]         256\n",
      "|    └─MaxPool2d: 2-21                   [-1, 128, 28, 28]         --\n",
      "|    └─Conv2d: 2-22                      [-1, 256, 28, 28]         295,168\n",
      "|    └─ReLU: 2-23                        [-1, 256, 28, 28]         --\n",
      "|    └─BatchNorm2d: 2-24                 [-1, 256, 28, 28]         512\n",
      "|    └─Conv2d: 2-25                      [-1, 256, 28, 28]         590,080\n",
      "|    └─ReLU: 2-26                        [-1, 256, 28, 28]         --\n",
      "|    └─BatchNorm2d: 2-27                 [-1, 256, 28, 28]         512\n",
      "|    └─MaxPool2d: 2-28                   [-1, 256, 14, 14]         --\n",
      "├─Sequential: 1-2                        [-1, 38]                  --\n",
      "|    └─Dropout: 2-29                     [-1, 50176]               --\n",
      "|    └─Linear: 2-30                      [-1, 1024]                51,381,248\n",
      "|    └─ReLU: 2-31                        [-1, 1024]                --\n",
      "|    └─Dropout: 2-32                     [-1, 1024]                --\n",
      "|    └─Linear: 2-33                      [-1, 38]                  38,950\n",
      "==========================================================================================\n",
      "Total params: 52,594,374\n",
      "Trainable params: 52,594,374\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 2.69\n",
      "==========================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 91.88\n",
      "Params size (MB): 200.63\n",
      "Estimated Total Size (MB): 293.09\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 256, 14, 14]         --\n",
       "|    └─Conv2d: 2-1                       [-1, 32, 224, 224]        896\n",
       "|    └─ReLU: 2-2                         [-1, 32, 224, 224]        --\n",
       "|    └─BatchNorm2d: 2-3                  [-1, 32, 224, 224]        64\n",
       "|    └─Conv2d: 2-4                       [-1, 32, 224, 224]        9,248\n",
       "|    └─ReLU: 2-5                         [-1, 32, 224, 224]        --\n",
       "|    └─BatchNorm2d: 2-6                  [-1, 32, 224, 224]        64\n",
       "|    └─MaxPool2d: 2-7                    [-1, 32, 112, 112]        --\n",
       "|    └─Conv2d: 2-8                       [-1, 64, 112, 112]        18,496\n",
       "|    └─ReLU: 2-9                         [-1, 64, 112, 112]        --\n",
       "|    └─BatchNorm2d: 2-10                 [-1, 64, 112, 112]        128\n",
       "|    └─Conv2d: 2-11                      [-1, 64, 112, 112]        36,928\n",
       "|    └─ReLU: 2-12                        [-1, 64, 112, 112]        --\n",
       "|    └─BatchNorm2d: 2-13                 [-1, 64, 112, 112]        128\n",
       "|    └─MaxPool2d: 2-14                   [-1, 64, 56, 56]          --\n",
       "|    └─Conv2d: 2-15                      [-1, 128, 56, 56]         73,856\n",
       "|    └─ReLU: 2-16                        [-1, 128, 56, 56]         --\n",
       "|    └─BatchNorm2d: 2-17                 [-1, 128, 56, 56]         256\n",
       "|    └─Conv2d: 2-18                      [-1, 128, 56, 56]         147,584\n",
       "|    └─ReLU: 2-19                        [-1, 128, 56, 56]         --\n",
       "|    └─BatchNorm2d: 2-20                 [-1, 128, 56, 56]         256\n",
       "|    └─MaxPool2d: 2-21                   [-1, 128, 28, 28]         --\n",
       "|    └─Conv2d: 2-22                      [-1, 256, 28, 28]         295,168\n",
       "|    └─ReLU: 2-23                        [-1, 256, 28, 28]         --\n",
       "|    └─BatchNorm2d: 2-24                 [-1, 256, 28, 28]         512\n",
       "|    └─Conv2d: 2-25                      [-1, 256, 28, 28]         590,080\n",
       "|    └─ReLU: 2-26                        [-1, 256, 28, 28]         --\n",
       "|    └─BatchNorm2d: 2-27                 [-1, 256, 28, 28]         512\n",
       "|    └─MaxPool2d: 2-28                   [-1, 256, 14, 14]         --\n",
       "├─Sequential: 1-2                        [-1, 38]                  --\n",
       "|    └─Dropout: 2-29                     [-1, 50176]               --\n",
       "|    └─Linear: 2-30                      [-1, 1024]                51,381,248\n",
       "|    └─ReLU: 2-31                        [-1, 1024]                --\n",
       "|    └─Dropout: 2-32                     [-1, 1024]                --\n",
       "|    └─Linear: 2-33                      [-1, 38]                  38,950\n",
       "==========================================================================================\n",
       "Total params: 52,594,374\n",
       "Trainable params: 52,594,374\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 2.69\n",
       "==========================================================================================\n",
       "Input size (MB): 0.57\n",
       "Forward/backward pass size (MB): 91.88\n",
       "Params size (MB): 200.63\n",
       "Estimated Total Size (MB): 293.09\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()  # this include softmax + cross entropy loss\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# batch gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gd(model , criterion , train_loader , validation_loader , epochs): \n",
    "    train_losses = np.zeros(epochs) \n",
    "    test_losses = np.zeros(epochs) \n",
    "\n",
    "    for e in range(epochs): \n",
    "        t0 = datetime.now() \n",
    "        train_loss = [] \n",
    "        for inputs ,targets in train_loader:\n",
    "            inputs , targets = inputs.to(device) , targets.to(device) \n",
    "            optimizer.zero_grad() \n",
    "            outputs = model(inputs) \n",
    "            loss = criterion(outputs , targets) \n",
    "            train_loss.append(loss.item()) \n",
    "            loss.backward()  \n",
    "            optimizer.step() \n",
    "        \n",
    "        train_loss = np.mean(train_loss) \n",
    "        validation_loss = [] \n",
    "\n",
    "        for inputs , targets in validation_loader:  \n",
    "            inputs , targets = inputs.to(device) , targets.to(device) \n",
    "            outputs = model(inputs) \n",
    "            loss = criterion(outputs , targets) \n",
    "            validation_loss.append(loss.item()) \n",
    "        validation_loss = np.mean(validation_loss) \n",
    "        train_losses[e] = train_loss \n",
    "        test_losses[e] = validation_loss \n",
    "\n",
    "        dt = datetime.now() - t0 \n",
    "        print(f\"Epoch {e+1}/{epochs} , train loss {train_loss:.3f} , test loss {validation_loss:.3f} , time {dt}\")\n",
    "    return train_losses , test_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "train_loader = torch.utils.data.DataLoader( \n",
    "    dataset , batch_size = batch_size , sampler = train_sampler \n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset , batch_size = batch_size , sampler = test_sampler\n",
    ") \n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    dataset , batch_size = batch_size , sampler = validation_sampler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 , train loss 3.899 , test loss 3.645 , time 0:13:56.451988\n",
      "Epoch 2/5 , train loss 3.619 , test loss 3.669 , time 0:14:57.910047\n",
      "Epoch 3/5 , train loss 3.555 , test loss 3.612 , time 0:15:19.290218\n",
      "Epoch 4/5 , train loss 3.533 , test loss 3.467 , time 0:15:05.269963\n",
      "Epoch 5/5 , train loss 3.486 , test loss 3.537 , time 0:15:38.562884\n"
     ]
    }
   ],
   "source": [
    "train_losses, validation_losses = batch_gd(\n",
    "    model, criterion, train_loader, validation_loader, 5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1- Underfits, when the training loss is way more significant than the testing loss.\n",
    "#### 2- Overfits, when the training loss is way smaller than the testing loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), 'plant_disease_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.89898883, 3.6188631 , 3.5554541 , 3.53257461, 3.4855126 ]),\n",
       " array([3.6450488 , 3.66938249, 3.6116027 , 3.46682437, 3.53723439]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_losses, validation_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ==================================== prediction ===================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import torch \n",
    "from torchvision import datasets , transforms , models \n",
    "from torch.utils.data.sampler import SubsetRandomSampler \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torchvision.transforms.functional as TF\n",
    "from datetime import datetime \n",
    "from PIL import Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module): \n",
    "    def __init__(self , K): \n",
    "        super(CNN , self).__init__() \n",
    "        self.conv_layers = nn.Sequential( \n",
    "            \n",
    "            #conv1 \n",
    "            nn.Conv2d(in_channels=3 , out_channels=32  , kernel_size=3 , padding=1),\n",
    "            nn.ReLU() ,\n",
    "            nn.BatchNorm2d(32) , \n",
    "            nn.Conv2d(in_channels=32 , out_channels=32 , kernel_size=3 , padding=1),\n",
    "            nn.ReLU() ,\n",
    "            nn.BatchNorm2d(32) , \n",
    "            nn.MaxPool2d(kernel_size=2 , stride=2) , \n",
    "\n",
    "            #conv2 \n",
    "            nn.Conv2d(in_channels=32 , out_channels=64 , kernel_size=3 , padding=1),\n",
    "            nn.ReLU() ,\n",
    "            nn.BatchNorm2d(64) , \n",
    "            nn.Conv2d(in_channels=64 , out_channels=64 , kernel_size=3 , padding=1),\n",
    "            nn.ReLU() ,\n",
    "            nn.BatchNorm2d(64) , \n",
    "            nn.MaxPool2d(kernel_size=2 , stride=2) , \n",
    "\n",
    "            #conv3 \n",
    "            nn.Conv2d(in_channels=64 , out_channels=128 , kernel_size=3 , padding=1),\n",
    "            nn.ReLU() ,\n",
    "            nn.BatchNorm2d(128) , \n",
    "            nn.Conv2d(in_channels=128 , out_channels=128 , kernel_size=3 , padding=1),\n",
    "            nn.ReLU() ,\n",
    "            nn.BatchNorm2d(128) , \n",
    "            nn.MaxPool2d(kernel_size=2 , stride=2) , \n",
    "            \n",
    "            #conv4 \n",
    "            nn.Conv2d(in_channels=128 , out_channels=256 , kernel_size=3 , padding=1),\n",
    "            nn.ReLU() ,\n",
    "            nn.BatchNorm2d(256) , \n",
    "            nn.Conv2d(in_channels=256 , out_channels=256 , kernel_size=3 , padding=1),\n",
    "            nn.ReLU() ,\n",
    "            nn.BatchNorm2d(256) , \n",
    "            nn.MaxPool2d(kernel_size=2 , stride=2) , \n",
    "        )\n",
    "\n",
    "        self.dense_layers = nn.Sequential( \n",
    "            nn.Dropout(0.4), \n",
    "            nn.Linear(50176 , 1024) ,\n",
    "            nn.ReLU() ,\n",
    "            nn.Dropout(0.4), \n",
    "            nn.Linear(1024 , K) ,\n",
    "        )\n",
    "\n",
    "    def forward(self , X): \n",
    "        out = self.conv_layers(X) \n",
    "\n",
    "        # Flatten \n",
    "        out = out.view(-1 , 50176) \n",
    "\n",
    "        # fully connected \n",
    "        out = self.dense_layers(out) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idx_to_classes = {0: 'Apple___Apple_scab',\n",
    "                  1: 'Apple___Black_rot',\n",
    "                  2: 'Apple___Cedar_apple_rust',\n",
    "                  3: 'Apple___healthy',\n",
    "                  4: 'Background_without_leaves',\n",
    "                  5: 'Blueberry___healthy',\n",
    "                  6: 'Cherry___Powdery_mildew',\n",
    "                  7: 'Cherry___healthy',\n",
    "                  8: 'Corn___Cercospora_leaf_spot Gray_leaf_spot',\n",
    "                  9: 'Corn___Common_rust',\n",
    "                  10: 'Corn___Northern_Leaf_Blight',\n",
    "                  11: 'Corn___healthy',\n",
    "                  12: 'Grape___Black_rot',\n",
    "                  13: 'Grape___Esca_(Black_Measles)',\n",
    "                  14: 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)',\n",
    "                  15: 'Grape___healthy',\n",
    "                  16: 'Orange___Haunglongbing_(Citrus_greening)',\n",
    "                  17: 'Peach___Bacterial_spot',\n",
    "                  18: 'Peach___healthy',\n",
    "                  19: 'Pepper,_bell___Bacterial_spot',\n",
    "                  20: 'Pepper,_bell___healthy',\n",
    "                  21: 'Potato___Early_blight',\n",
    "                  22: 'Potato___Late_blight',\n",
    "                  23: 'Potato___healthy',\n",
    "                  24: 'Raspberry___healthy',\n",
    "                  25: 'Soybean___healthy',\n",
    "                  26: 'Squash___Powdery_mildew',\n",
    "                  27: 'Strawberry___Leaf_scorch',\n",
    "                  28: 'Strawberry___healthy',\n",
    "                  29: 'Tomato___Bacterial_spot',\n",
    "                  30: 'Tomato___Early_blight',\n",
    "                  31: 'Tomato___Late_blight',\n",
    "                  32: 'Tomato___Leaf_Mold',\n",
    "                  33: 'Tomato___Septoria_leaf_spot',\n",
    "                  34: 'Tomato___Spider_mites Two-spotted_spider_mite',\n",
    "                  35: 'Tomato___Target_Spot',\n",
    "                  36: 'Tomato___Tomato_Yellow_Leaf_Curl_Virus',\n",
    "                  37: 'Tomato___Tomato_mosaic_virus',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_obj , idx_to_classes): \n",
    "    INPUT_DIM = 224 \n",
    "\n",
    "    preprocess = transforms.Compose([ \n",
    "        transforms.Resize(INPUT_DIM) , \n",
    "        transforms.CenterCrop(INPUT_DIM) , \n",
    "        transforms.ToTensor() , \n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406] , std=[0.229, 0.224, 0.225]) ,\n",
    "    ]) \n",
    "\n",
    "    pretrained_model = CNN(38) \n",
    "    pretrained_model.load_state_dict( \n",
    "        torch.load('plant_disease_model.pt' , map_location=torch.device('cuda'))  \n",
    "    ) \n",
    "\n",
    "    im = image_obj \n",
    "    im_preprocessed = preprocess(im) \n",
    "    batch_img_tensor = torch.unsqueeze(im_preprocessed , 0) \n",
    "    print(type(batch_img_tensor))\n",
    "    output = pretrained_model(batch_img_tensor)\n",
    "    output = output.detach().numpy()  \n",
    "    index = np.argmax(output) \n",
    "    predicted_class = idx_to_classes[index] \n",
    "    confidence = np.max(output[0])  \n",
    "    return predicted_class , confidence*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.JpegImagePlugin.JpegImageFile'>\n",
      "<class 'torch.Tensor'>\n",
      "predicted class : Corn___Cercospora_leaf_spot Gray_leaf_spot \n",
      " confidence : 447.4454879760742\n"
     ]
    }
   ],
   "source": [
    "file_input = './data/test/test/CornCommonRust1.JPG'\n",
    "im = Image.open(file_input)\n",
    "print(type(im))\n",
    "result = predict(im , idx_to_classes)\n",
    "print(f\"predicted class : {result[0]} \\n confidence : {result[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(image_path ,idx_to_classes): \n",
    "\n",
    "    model = CNN(38)    \n",
    "    model.load_state_dict(torch.load(\"plant_disease_model.pt\"))\n",
    "    model.eval()\n",
    "\n",
    "    image = Image.open(image_path) \n",
    "    image = image.resize((224, 224)) \n",
    "    input_data = TF.to_tensor(image) \n",
    "    input_data = input_data.view(-1 , 3 , 224 , 224) \n",
    "    output = model(input_data)  \n",
    "    output = output.detach().numpy()  \n",
    "    index = np.argmax(output) \n",
    "    predicted_class = idx_to_classes[index] \n",
    "    confidence = np.max(output[0])  \n",
    "    return predicted_class , confidence*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class : Corn___Cercospora_leaf_spot Gray_leaf_spot \n",
      " confidence : -445.97320556640625\n"
     ]
    }
   ],
   "source": [
    "file_input = './data/test/test/CornCommonRust1.JPG'\n",
    "result = prediction(file_input , idx_to_classes)\n",
    "print(f\"predicted class : {result[0]} \\n confidence : {result[1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
